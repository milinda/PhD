\documentclass{sig-alternate}

%\usepackage[urw-garamond]{mathdesign}
%\usepackage[T1]{fontenc}

\usepackage{hyperref}


% SIG Alternate copyright removal
\usepackage{etoolbox}
\makeatletter
\patchcmd{\maketitle}{\@copyrightspace}{}{}{}
\makeatother

\usepackage[usenames,dvipsnames]{color}


\begin{document}
%
% --- Author Metadata here ---
\CopyrightYear{2014} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{Benchmark Suite to Evaluate Performance of Distributed Stream
  Processing Platforms}

\numberofauthors{2}

\author{
% 1st. author
\alignauthor
Milinda Pathirage\\
       \affaddr{School of Informatics and Computing}\\
       \affaddr{Indiana University}\\
       \email{mpathira@indiana.edu}
% 2nd. author
\alignauthor
Beth Plale\\
       \affaddr{School of Informatics and }\\
       \affaddr{Indiana University}\\
       \email{plale@cs.indiana.edu}
}

\maketitle
\begin{abstract}
  Interest on continuous queries on streams of data has increased over last couple of years due to
  the need of derving actionable information as soon as possible
 to be competitive in the fast moving world. As a result of the limitations
 in batch processing technologies from previous generation, distributed
 stream processing systems like Yahoo's \textit{S4}, Twitter's \textit{Storm}, \textit{Spark
 Streaming} were introduced into the fast growing Big Data eco-system.
 Even though there are various different stream processing platforms
 and frameworks on top of them with different capabilities and
 characteristics, in-depth comparative studies of performance, scalability and
 reliability has never been done. Users of these system often face
 difficulties when choosing a system as a solution to a task at hand.
 In this paper we use some of the popular distributed stream
 processing use cases we identified by going through mailing list
 discussions, presentations and publication to evaluate three (
 \textit{Storm, Spark Streaming, Samza}) of the
 most popular distributed processing systems used widely today.
\end{abstract}

% A category with the (minimum) three required fields
%\category{Data streams}{Please fix.}{Please fix.}
%A category including the fourth, optional field follows...
%\category{D.2.8}{Please fix.}{Metrics}[complexity measures,
%performance measures, please fix.]

%\terms{Fix this.}

%\keywords{Fix this.}

\section{Introduction}
Internet has become a central part of our daily lives and recent developments in
\textit{Smart Phones}, \textit{Internet of Things} and \textit{Smart Homes} related
technologies are going to make us more connected through Internet more than ever.
As more and more people and devices are connected together via web applications which
Internet is built, these application will produce massive amount of data at rates which
we haven't experienced yet. In parallel to the increase of data generation, business
entities and users require this data and information extracted or created out of this data
available to them as fast as possible and trending towards decreasing latency for ever.

\begin{sloppypar}
As we have experienced in recent past, traditional relational database
technologies couldn't
cope up with these ever increasing data rates, volumes and ever decreasing latency. So technology
giants like Google, Yahoo and Amazon invented  novel storage
technologies like GFS~\cite{ghemawat2003google}, HDFS, Big Table~\cite{chang2008bigtable} and
Amazon Dynamo~\cite{decandia2007dynamo} and distributed data processing frameworks such as Map-Reduce~\cite{dean2010mapreduce}.
As the trend continues, these systems which follow traditional pull based approach
to answering queries couldn't handle the latency requirements and throughput requirements,
\textit{Distributed Stream Processing} platforms were built on top of modern messaging
infrastructures to fulfill these requirements. While most of these new
distributed stream processing frameworks are inspired by Map-Reduce
and related big data technologies, most of the underlying concepts
were from previous work.\textcolor{Red}{Add references and fix this.}
\end{sloppypar}

With this trend of moving to push based streaming processing platforms
for reducing the latency and to handle increasing throughput
requirements, several distributed and single-node stream processing
platforms were implemented and they are continue to evolve to tackle
ever changing requirements. But due to different architectural
decisions underlying these platforms and variations in problem classes and
non-functional requirements these frameworks are trying to address,
these frameworks behave differently under different types of data and
algorithms. \textcolor{Red}{Need references.} Also these systems
support different types of programming abstractions. These variations
make the decision of selecting a specific platform hard. Although
there are existing results on how these platforms perform
individually \textcolor{Red}{(Need references.)}, but its hard to find
comparative studies. In this paper, we present a comprehensive
framework for analyzing and comparing distributed stream processing
platforms. Further, we implement benchmark algorithms from our
 framework on several popular stream processing platforms and present
 our findings evaluating their performance, scalability, fault tolerance
 and ease of use.

 We envision that, having defined framework and set of benchmark applications
 will help stream analysts and developers who requires to use these systems to
 make informed decisions. However functional and non-functional characteristics
 of stream processing systems depends mainly on types of data, streaming analysis
 task, stream processing platform and the infrastructure used (persistence storage
 used to store output, messaging middleware used to deliver data streams). However,
 we keep the infrastructure constant across stream processing platforms during our
 experiments and propose a framework which can use to analyze stream processing
 platforms across three dimensions \texit{type of streaming data, stream processing
   algorithms,} and \texit{stream processing platform}.








 \subsection{Event Stream Processing Tasks}


From~\cite{streamdrill:presentation}

 \textbf{Tasks by Complexity(Increasing Order)}

 \begin{itemize}
  \item Counting, Averages and Count Distinct
  \item Profiles and Histograms
  \item Trends
  \item Outliers and Fraud Detection
  \item Prediction (churn, failure)
 \end{itemize}

\textbf{Tasks by Latency(Decreasing Order)}
\begin{itemize}
 \item Reporting
 \item Visualization and Monitoring
 \item Optimizing, Personalizations
 \item Control
\end{itemize}

\section{Benchmaking Suite and Methodology}

\subsection{Properties of Applications}

All application must output results to a persistence storage (\textbf{or just to memory}) and same
storage should be used across every platform. We should try to factor out the effect of storage by
keeping it constant.

\section{Resources}

\begin{itemize}
 \item CS49: Data Stream Algorithms - \url{http://www.cs.dartmouth.edu/~ac/Teach/CS49-Fall11/Notes/lecnotes.pdf}
 \item A Comparison of Approaches to Large-Scale Data Analysis - \url{http://database.cs.brown.edu/sigmod09/benchmarks-sigmod09.pdf}
 \item An Empirical Study of High Availability in Stream Processing Systems - \url{http://users.nccs.gov/~zzhang3/pubs/empirical-middleware09.pdf}
   \item A Hybrid Approach to High Availability in Stream Processing Systems - \url{http://irl.cs.ucla.edu/~yefan/papers/ICDCS10.pdf}
\end{itemize}

\bibliographystyle{abbrv}
\bibliography{main}
\end{document}
