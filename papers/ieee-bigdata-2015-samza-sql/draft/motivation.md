# Samza SQL: Motivation
In todays data driven economy, more and more business organisations depend on timely analytics of data they accumulate to stay competitive. There is a saying that before becoming big the data was fast. This is because of the fact that most of the big data are result of accumulating events from sensors, devices, click streams, server logs and other form of user activity logs. Normally big data is generated by these fast data or events happening at scale of tens of thousands to hundreds of thousand events pr second. To get most out of this data, timely analytics is needed. We can categorize these data processing systems or tasks into three categories based on their latency requirements.

* Online/Realtime - Queries on fast data in realtime and may refer slow-changing or static data for data enrichment. Most of the times latency requirements are in the order of milliseconds
* Nearline - Queries on fast data but latency requirements are in the order of seconds. *Sooner these systems provide results, the higher the value to the end user **from lquid** *.
* Offline - Latency requirements are in order of minutes or hours. OLAP queries and Map/Reduce jobs are typical examples.

Above mention analytics tasks are often interconnected **from trill** and often realtime and nearline analytics tasks used historical information which may be results from offline/batch analytics tasks. Different solutions and architectures were proposed to unify the way we handle this interconnection between different types of analytics. 

Lambda arhcitecture is one of these architectural frameworks and there several implementations available. In this architecture, there are three main components or layers to handle fast data, big data and serving queries based on results from fast data component and big data component. In the context of Lambda architecture these layers are know as

- Speed Layer
- Batch Layer
- Service Layer 

Then there is another group of people who propsed completely different architecture know as Kappa architecture for handling this problem. Their argument is to use stream processing system with materialized views to handle both speed and batch analytics tasks. You will expressed your analytics task as a stream processing algorithm and replying input streams will be used to simulate the batch layer. One advantage of this method is you can reuse the same applicaiton/algorithm for both speed and batch layer with extra management capabilities in stream processing framework to support replay and materialize view management.

But as we know, current implementations of Lamda architecture and Kappa architecture both require users to use a programming APIs in high-level languages or query languages that looks like SQL (Druid) but with different set of semantics. Also our experience with Lambda architecture framework like Summingbird shows that understanding of complex programming abstractions are required to take the advantage of these frameworks. Also managing data analytics applications written for these may incur extra maintenance overhead. 

So Kappa/Lambda arhcitecture implementation which provides DBMS like capabilities is required to make these fast data analytics frameworks accessible to broad community of users. Wide adoption of Hive and Drill like frameworks to query Big Data is a good indicator for requirement of SQL based analytics for Big Data and in this work we try to provide same capabilities provided by Hive for Big Data to Fast Data analytics using Samza SQL. Also we envision that SQL compliant fast data management system will make fast data analytics accessible to broad community of users because they can utilize knowledge of SQL in the context of fast data analytics. 

Also its a known fact that online and nearline analytics often interact with static or slow-changing data sources. So we wanted our system to allow access to slow-changing data sources within streaming SQL queries. In addition to that to enable users to utilize their existing knowledge of SQL, its important to support standard SQL with minimal extensions to support streaming specific scenarios. 

Given that today's applications use different data formats such as JSON, Avro or Protocol Buffers to communicate, its important that the fast data management solution supports pluggable message formats. 

Also fault tolrenace and scalability is impotant at the internet scale and its important that this SQL based solution take adavantage of existing fault tolrenance and scalability features in the underlying stream processing system. 

When processing streaming data, its important to have support for proper window operations to handle different windowed aggregation scenarios and these window processing infrastrcture should support fault tolerance and delayed events.

Even though Kappa architecture sounds promising, but adding a SQL layer in-front solves several drawbacks of Lambda architecture such as having to maintain two different code bases for streaming and batch. So its important this framework to support compiling of SQL queries to both batch and streaming tasks.

## Liquid: Motivation Notes

- Discuss different requirements. Latency requirements and what is special about these tasks.
- Then discuss about current approaches and their problems. Current approaches include Lambda Architecture and Kappa Architecture.

